% -*- root: 00-main.tex -*-
\section{Results}
\label{sec:results}

\subsection{Proof of concept on digital phantoms}
\label{sec:results_phantom}

\begin{figure*}
    \centering
    \resizebox{\textwidth}{!}{%
      \begin{tikzpicture}
        \node[inner sep=10pt, draw=black!40](fig03b) at (0,7.9)
          {\hspace*{20pt}\includegraphics[width=\linewidth]{figures/figure03-b}};
        \node[inner sep=10pt, draw=black!40](fig03c) at (0,0)
          {\hspace*{20pt}\includegraphics[width=\linewidth]{figures/figure03-c}};
        \node[circle, text=black!75] at (-9.4,10.6) {\Huge \textbf{A}};
        \node[circle, text=black!75] at (-9.4,3.5) {\Huge \textbf{B}};
      \end{tikzpicture}
    }%
  \caption{A. Visual assessment of the results on the low resolution sets:
    ``gyrus'' (top-left), ``L-shape'' (top-right), ``ball'' (bottom-left),
    and ``box'' at (bottom-right).
  In yellow color, the recovered contours after registration are represented.
  Our method showed high accuracy, as it demonstrates the almost exact location of the registered
    contours with respect to their ground truth position depicted in green.
  Partial volume effect turns segmentation of the sulci a challenging problem with voxel-wise
    clustering methods, but it is successfully segmented with our method.
  B. Quantitative evaluation of registration error in terms of average Hausdorff distance of
    surfaces at low (left) and high (right) resolutions, demonstrating that the error is
    consistently below the voxel size.
    }\label{fig:phantom}
\end{figure*}
A total of 1200 experiments (4 phantom types $\times$ 150 random warpings $\times$ 2 resolutions) were
  run using the workflow given in \autoref{fig:evphantoms}.
For each experiment, the misregistration error was measured using the Hausdorff distance
  (see \autoref{sec:experiments_evaluation}) between the theoretical $\gammaset_\text{true}$ and
  the estimation done by \emph{regseg} ($\hat{\gammaset}_{test}$).
The results showed a consistent and high accuracy, below the image resolution.
\autoref{fig:phantom} (block C) presents the violin plots by model type corresponding
  to the two sets of resolutions of generated phantoms.
In order to relate average misregistration error to the resolution of the moving image,
  we proceeded as follows.
First, we confirmed that the vertex-wise error distributions were skewed using a Shapiro-Wilk test of
  normality.
All the distributions of errors under test (4 phantom types $\times$ 2 resolutions) resulted
  non-normal with $p<0.001$.
Consequently, we used the non-parametric Wilcoxon signed-rank test along with Bonferroni
  correction for multiple comparisons ($N=150$, for each phantom type).
Averaged errors resulted significantly lower than voxel size with $p < (0.001 / 150)$
  for all the tests (4 phantom types $\times$ 2 resolutions).
Since statistical tests may not be conclusive enough, we also computed the confidence intervals,
  reported in \autoref{tab:ci_phantom}.


\begin{table}
		\centering
		\footnotesize
    \begin{tabular}{lccccc}
    Res. & ``gyrus'' & ``ball''  & ``box''   & ``L''     & Aggreg.    \\\hline
    Low  & 0.59-0.60 & 0.65-0.76 & 0.68-0.71 & 0.67-0.77 & 0.64-0.66  \\
    High & 0.18-0.38 & 0.31-0.45 & 0.34-0.42 & 0.34-0.40 & 0.34-0.38  \\
    \hline
    \end{tabular}
    \caption{95\% Confidence Intervals (CIs) were computed using bootstrapping of $10^4$ samples,
      for each phantom type and resolution.
    Taking into account the non-normal distribution of errors, we used the median as location
  		statistic.
    All the CIs were below the corresponding half-voxel size in all the phantom types.}\label{tab:ci_phantom}
\end{table}

\subsection{Evaluation on real datasets and cross-comparison}\label{sec:results_hcp}
%
Finally, we compared the performance of \emph{regseg} and the standard \gls*{t2b}
  registration.
We computed the \gls*{swindex} \eqref{eq:swindex} of every surface after registration,
  for both \emph{regseg} and the \gls*{t2b} methods.
Finally, to statistically compare the results, we performed a one-way ANOVA test
  on the warping indices for three specific surfaces of interest
  ($\Gamma_{VdGM}$, $\Gamma_{WM}$, and $\Gamma_{pial}$).
These interfaces are critical in analyses of whole-brain tractography.
The one-way ANOVA evidenced that error distributions were significantly different,
  $p \approx 2 \times 10^{-9}$.
We also reported the 95\% CIs of the \gls*{swindex} for those surfaces.
The aggregate CI for \emph{regseg} was 1.08 - 1.50 [mm], whereas the \gls*{t2b} method
  yielded an aggregate CI of 2.06 - 2.43 [mm].
The quantitative results of the ANOVA tests and the CIs are presented in \autoref{tab:results_real}.
Visual assessment of the 16 cases is included in the \suppl{section S5}.
In \autoref{fig:results_real}, box A, the visual report for one subject is supplied.
Box B presents the corresponding violin plots of error distributions by registration method
  and surface.

\begin{table}
		\centering
		\footnotesize
		\tabcolsep=0.05cm
    \begin{tabular}{cccccc}
    & & $\Gamma_{VdGM}$  & $\Gamma_{WM}$ & $\Gamma_{pial}$ & Aggregate \\
    \hline
    \multirow{2}{*}{CI}
       & \emph{regseg}        & 0.50 - 0.78 & 0.50 - 0.55 & 0.66 - 0.73 & 0.56 - 0.66 \\
       & T2B                  & 1.78 - 2.58 & 1.94 - 2.36 & 2.16 - 2.58 & 2.05 - 2.39 \\
    \hline
    \multirow{2}{*}{ANOVA}
       & p-value  & 1.5$\times$10$^{-8}$& 6.3$\times$10$^{-16}$& 4.2$\times$10$^{-16}$ & 4$\times$10$^{-34}$ \\
       & f-stat   & 60.03               & 255.82               & 263.97                & 377.82              \\
    \hline
    \end{tabular}
    \caption{All the 95\% CIs of the \gls*{swindex} distributions computed for the
      surfaces of interest were lower for \emph{regseg} with respect to the competing
      method.
    CIs reported in this table were computed using bootstrapping with mean as location
      statistic and $10^4$ samples.
    One-way-ANOVA tests indicated that there is a significant difference between our method and
      the competing method of choice.
    }\label{tab:results_real}
\end{table}

\begin{figure*}
    \centering
    \resizebox{\textwidth}{!}{%
      \begin{tikzpicture}
        \node[inner sep=15pt, draw=black!40](fig05a) at (0,11)
          {\hspace*{20pt}\includegraphics[width=\linewidth]{figures/figure05-a}};
        \node[inner sep=15pt, draw=black!40](fig05b) at (0,0)
          {\hspace*{20pt}\includegraphics[width=\linewidth]{figures/figure05-b}};
        % \node[inner sep=5pt, draw=black!40](fig03c) at (0,0)
        %   {\includegraphics[width=\linewidth]{figures/figure03-c}};
        \node[circle, text=black!75] at (-9.5,17) {\Huge \textbf{A}};
        \node[circle, text=black!75] at (-9.5,3) {\Huge \textbf{B}};
        % \node[circle, text=black!75] at (-8.8,3.4) {\Huge \textbf{C}};
      \end{tikzpicture}
    }%
	\caption{The evaluation instrument automatically renders the overlay between the
	  target \gls*{fa} image and the resulting contours after distortion estimation (yellow color) and
	  their theoretical location using the ground-truth (green color).
	The first two rows show several axial slices for \emph{regseg} (``proposed'' row) and the
	  competing method.
	The last two rows represent the sagittal view.
	We intentionally omitted the coronal slicing as it is the least informative, given the directional property
	  of distortions.
	Red arrows point to regions where the accuracy of the proposed method more clearly overperformed
	  the competing method.
	}\label{fig:results_real}
\end{figure*}