% -*- root: 00-main.tex -*-
\section*{Results and discussion}
\label{sec:results}

\subsection*{Proof of concept on digital phantoms}
\label{sec:results_phantom}
Using the experimental instrumentation described in section \nameref{sec:experiments_evaluation},
  we fine tuned the algorithm for its use on real data and collected quantitative results.
To warp the simulated datasets, we generated 150 realizations of random and smooth displacement
  fields $U^{-1}_{true}$.
Smoothness is achieved using two levels of B-Spline functions, with control points evenly
  located in isotropic grids covering the full extent of the model.
The first level had $50.5mm$ of separation between control points and the second $25.25mm$.
The rationale behind this choice is producing large deformations on the contours with
  the first level, and matching the properties of susceptibility-derived distortions
  as previously reported by \cite{irfanoglu_susceptibility_2011} with the finer grid.
Invertibility of $U^{-1}_{true}$ is ensured by controlling the maximum displacement at each
  level ($20.2mm$ and $10.1mm$ respectively) as studied in \citep{rueckert_diffeomorphic_2006}.

A total of 1200 registration experiments (4 phantom types $\times$ 150 random warpings
  $\times$ 2 resolutions) were run.
For each registration, the averaged Hausdorff distance (see \nameref{sec:experiments_evaluation})
  of the inner and the outer surfaces was computed.
The results showed a consistent and high accuracy, below voxel resolution.
\autoref{fig:phantom} (block C) presents the box plots by model type corresponding
  to the two sets of resolutions of generated phantoms.
To support that the missregistration errors averaged per experiment was significantly
  under the resolution of the target image, we proceeded as follows.
First, we confirmed that the error distributions were skewed using a Shapiro-Wilk test of
  normality.
All the distributions of errors under test (4 phantom types $\times$ 2 resolutions) resulted
  non-normal with $p<0.001$.
Consequently, we used the non-parametric Wilcoxon signed-rank test along with Bonferroni
  correction for multiple comparisons ($N=150$).
Averaged errors resulted significantly lower than voxel resolution with $p < (0.001 / 150)$
  for all the tests (4 phantom types $\times$ 2 resolutions).

\subsection*{Distortion correction on real datasets}
\label{sec:results_hcp}

As we propose the \gls*{fa} and the \gls*{md} as target features, we
  implemented a simplified pipeline for processing \gls*{dmri} using
  \emph{MRtrix} \citep{tournier_mrtrix_2012}.
\todo[inline]{insert here the summary of parameters}

Selecting the appropriate labels in the \emph{aparc} segmentation, we applied
  the marching-cubes algorithm again to extract priors of the following
  homogeneous regions in terms of \gls*{fa} and \gls*{md} joint distribution:
\begin{itemize}
	\item \gls*{csf} of the ventricular system,
	\item deep \gls*{gm} structures,
	\item \gls*{wm} surface as the ensemble of brain stem, and
	  cerebellar and cerebral \gls*{wm},
	\item cortical \gls*{gm} surface, including cerebellar \gls*{gm}.
\end{itemize}

\subsection*{Discussion}
\label{sec:discussion}
We propose a registration-segmentation algorithm designed for biomedical
  image analyses that are affected by all or some of the following circumstances:
  \begin{itemize}
  	\item Reference and target images do not present appropriate contrasts to
  	perform volume-based registration reliably, or there is not available an apt image
 		to be used as reference.
  	\item The low resolution of the target volume produces strong partial volume effects
  	that exclude the use of voxel-wise segmentation algorithms and hinder volume-based
  	registration.
  	\item The unknown warping is smooth enough to be represented with a sufficient number
  	of BSpline kernels, and its explicit need is justified (i.e. the distortion
  	field in \gls*{dmri} images, object tracking applications, etc.).
  \end{itemize}
The algorithm is designed for the proposed application on correcting distortions of
  \gls*{dmri} data, a required preliminary step to extract the structural connectivity
  networks.
As a consequence, our approach relies on the availability of precise segmentations or
  surfaces of the objects that are to be segmented on the target volume(s).
Connectome extraction protocols generally include the acquisition of \gls*{t1} images
  to provide with prior information about anatomy with high accuracy.
\todo[inline]{Add sentence about comment RW\#1 of IPMI2013: incorporate knowledge of
the EPI distortions into regularization}
Our method solves in a single step a joint problem usually addressed in two steps.
The first solves the linear registration of the \gls*{t1} and \gls*{dmri} data (i.e.
  \cite{greve_accurate_2009}), whereas the second corrects for the nonlinear distortions
  derived from the inhomogenety of magnetic susceptibility across tissues
  \citep{jezzard_correction_1995}.

{\color{red} We also considered the reproducibility of results a design requirement.
Therefore, real data are fetched from a publicly available repository
  (the Human Connectome Project \citep{essen_human_2012}) and all the software
  involved in this paper is also publicly released.
\autoref{fig:evworkflows} describes the general structure of the workflow we implemented
  as evaluation instrument, using \emph{nipype} \citep{gorgolewski_nipype_2011} to ensure
  reproducibility.}

We implemented the registration method upon the widely used Insight Registration and Segmentation
	Toolkit (\url{http://www.itk.org}) with the aim to release a useful and free software bundle.
The instrumentation framework is also distributed with the registration method,
  and has been implemented using \emph{nipype} \citep{gorgolewski_nipype_2011}.
The pipelines include the automatic generation of the ``cortex'' phantom.
The real datasets are publicly available under the \gls*{hcp} project.
Thus, all the experiments and results presented in this paper are intended to be
  fully reproducible.